{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "0j2OXL0zfPK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "if \"google.colab\" in sys.modules\n",
        "    os.makedirs(\"/content/qk-spectral-analysis\", exist_ok=True)\n",
        "    os.chdir(\"/content/qk-spectral-analysis\")\n",
        "else:\n",
        "    os.makedirs(\"qk-spectral-analysis\", exist_ok=True)\n",
        "    os.chdir(\"qk-spectral-analysis\")\n",
        "\n",
        "!pip install papermill\n",
        "\n",
        "# Run this to download figures, ESDs, and code.\n",
        "# !git clone https://github.com/SD-interp/qk-spectral-analysis.git\n",
        "\n",
        "# Run this to only fetch python dependencies\n",
        "! wget https://raw.githubusercontent.com/SD-interp/qk-spectral-analysis/refs/heads/main/utils.py\n",
        "! wget https://raw.githubusercontent.com/SD-interp/qk-spectral-analysis/refs/heads/main/models.py\n"
      ],
      "metadata": {
        "id": "9sydo_U9DorL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute ESD and generate plots\n",
        "\n",
        "This notebook downloads pretrained transformer weights (e.g., Qwen3-4B),\n",
        "extracts the Query and Key projection matrices (`W_Q`, `W_K`),\n",
        "computes their singular-value spectra, and generates plots for `Classification_A` and `Classification_B`.\n",
        "\n",
        "The target model family can be specified by setting the `family` variable.\n",
        "Model lists for each family are defined in `models.py`.\n",
        "\n",
        "You can extend support for new models or families by editing `models.py`.\n",
        "Each model should follow the standard file and layer naming conventions\n",
        "and be accessible as `.safetensors` files.\n",
        "\n",
        "Processed results are saved to `/content/qk-spectral-analysis/{model_family}/data/`."
      ],
      "metadata": {
        "id": "8Tb2ycaSp7Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "family = \"Qwen3\" #Qwen3 Gemma2 Llama Mistral"
      ],
      "metadata": {
        "id": "qo58QYj8qufY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5yIKkBRjBe-"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "from safetensors.torch import load_file, load\n",
        "from huggingface_hub import hf_hub_download, HfApi\n",
        "from transformers import AutoConfig\n",
        "import einops\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import threading\n",
        "import queue\n",
        "import random\n",
        "from functools import partial\n",
        "import time\n",
        "from models import get_model_names\n",
        "from utils import robust_lowrank_singular_values, get_stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.set_grad_enabled(False)\n",
        "t.manual_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "api = HfApi()\n",
        "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
        "\n",
        "models = get_model_names(family)\n",
        "os.makedirs(f\"{family}/data\", exist_ok=True)"
      ],
      "metadata": {
        "id": "8CCY2ahL2e7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Run download and processing on separate threads for efficiency.\n",
        "Save to drive in RAM to reduce write-times.\n",
        "Delete files once processed to free up disk space.\n",
        "\"\"\"\n",
        "\n",
        "records = defaultdict(dict)\n",
        "\n",
        "def download_worker():\n",
        "    for filename in files_to_download:\n",
        "        print(f\"‚¨áÔ∏è Downloading {filename} ...\")\n",
        "        path = hf_hub_download(\n",
        "            repo_id=model_name, filename=filename, local_dir=\"/dev/shm\")\n",
        "        file_queue.put(path)  # send to GPU worker\n",
        "        print(f\"‚úÖ Downloaded {filename}\\n\")\n",
        "    file_queue.put(None)  # signal completion\n",
        "\n",
        "def gpu_worker():\n",
        "    while True:\n",
        "        path = file_queue.get()\n",
        "        if path is None:  # download finished\n",
        "            file_queue.put(None)\n",
        "            break\n",
        "        print(f\"üö© Starting processing {os.path.basename(path)}\")\n",
        "\n",
        "        tensors = load_file(path, device=device)\n",
        "        os.remove(path) # delete file after loading\n",
        "\n",
        "        for tensor_name in tensors:\n",
        "            if \"q_proj\" not in tensor_name:\n",
        "                continue\n",
        "\n",
        "            q_name = tensor_name\n",
        "            k_name = tensor_name.replace(\"q_proj\", \"k_proj\") # Look for correspoding k-proj\n",
        "            layer = int(re.search(r\"layers\\.(\\d+)\\.\", q_name).group(1))\n",
        "\n",
        "            assert k_name in tensors, f\"key tensor not found for layer {layer}\"\n",
        "\n",
        "            # Using t.float64 does not have noticeable difference\n",
        "            W_Q = tensors[q_name].to(t.float32)\n",
        "            W_K = tensors[k_name].to(t.float32)\n",
        "\n",
        "            W_Q = einops.rearrange(W_Q,\n",
        "                \"(q_head d_head) d_model -> q_head d_head d_model\", q_head=n_heads)\n",
        "            W_K = einops.rearrange(W_K,\n",
        "                \"(k_head d_head) d_model -> k_head d_head d_model\", k_head=n_kv_heads)\n",
        "\n",
        "            # if GQA repreat W_K to match W_Q\n",
        "            if n_heads != n_kv_heads:\n",
        "                ratio = n_heads//n_kv_heads\n",
        "\n",
        "                W_K = t.repeat_interleave(W_K, dim=0, repeats=ratio)\n",
        "                assert t.equal(W_K[0], W_K[1]), f\"incorrect repetition order\"\n",
        "\n",
        "            # compute singular and eigen values\n",
        "            singular_values = robust_lowrank_singular_values(W_Q, W_K)\n",
        "            eigen_values = singular_values ** 2\n",
        "\n",
        "            records['singular_values'][layer] = singular_values.cpu().numpy()\n",
        "            svd_stats = get_stats(singular_values)\n",
        "            records['singular_values_stats'][layer] = svd_stats\n",
        "\n",
        "            records[\"eigen_values\"][layer] = eigen_values.cpu().numpy()\n",
        "            eigen_stats = get_stats(eigen_values)\n",
        "            records['eigen_values_stats'][layer] = eigen_stats\n",
        "\n",
        "        print(f\"‚òëÔ∏è Completed processing {os.path.basename(path)}\\n\")\n",
        "\n",
        "    with open(f\"{family}/data/{model_name.split('/')[-1]}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(records, f)\n",
        "\n",
        "def run():\n",
        "\n",
        "    t1 = threading.Thread(target=partial(download_worker), daemon=True)\n",
        "    t2 = threading.Thread(target=gpu_worker, daemon=True)\n",
        "\n",
        "    t1.start()\n",
        "    t2.start()\n",
        "\n",
        "    t1.join()\n",
        "    t2.join()"
      ],
      "metadata": {
        "id": "6319pq2KvoB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "done = os.listdir(f\"{family}/data\")\n",
        "# Skip processing if summary file exists\n",
        "models = [x for x in models if x.split('/')[-1]+\".pkl\" not in done]\n",
        "\n",
        "for model_name in tqdm_notebook(models):\n",
        "    files_to_download = [x for x in api.list_repo_files(model_name) if x.endswith(\".safetensors\") and \"model\" in x.casefold()]\n",
        "    cfg = AutoConfig.from_pretrained(model_name) # get model config dict\n",
        "\n",
        "    d_model = cfg.hidden_size\n",
        "    d_head = cfg.head_dim\n",
        "    n_heads = cfg.num_attention_heads\n",
        "    n_kv_heads = getattr(cfg, \"num_key_value_heads\", n_heads)\n",
        "\n",
        "    file_queue = queue.Queue()\n",
        "    records = defaultdict(dict)\n",
        "    run()\n",
        "    print(f\"completed {model_name}\\n\\n\")\n",
        "    time.sleep(0.5)"
      ],
      "metadata": {
        "id": "dUXIvcjE3BMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For Colab\n",
        "Use these cells if you cannot run the other scripts directly"
      ],
      "metadata": {
        "id": "gPhRVHwfEYiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import papermill as pm\n",
        "_ = pm.execute_notebook(\"/content/Classification_A.ipynb\", \"/content/Classification_A_out.ipynb\")\n",
        "_ = pm.execute_notebook(\"/content/Classification_B.ipynb\", \"/content/Classification_B_out.ipynb\")"
      ],
      "metadata": {
        "id": "I4oB3mdAEDjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GXwOWTQ1iQSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}